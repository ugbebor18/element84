name: Deploy Infrastructure and Lambda

on:
  push:
    branches:
      - main

jobs:
  deploy:
    name: Terraform Deployment and Lambda Updates
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout Code
      - name: Checkout code
        uses: actions/checkout@v3

      # Step 2: Set Up Terraform
      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.3

      # Step 3: Terraform Init
      - name: Initialize Terraform
        run: terraform init

      # Step 4: Terraform Apply Backend
      - name: Deploy Backend
        run: terraform apply -target=aws_s3_bucket.terraform_state -target=aws_dynamodb_table.terraform_locks -auto-approve

      # Step 5: Terraform Apply Infra Resources
      - name: Deploy Resources
        run: terraform apply -auto-approve

      # Step 6: Package Lambda Function
      - name: Package Lambda
        run: |
          zip lambda_function.zip infra/lambda_function.py

      # Step 7: Deploy Lambda Function
      - name: Deploy Lambda Function
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          aws lambda update-function-code \
            --function-name merge-homeless-data \
            --zip-file fileb://lambda_function.zip

      # Step 8: Upload CSV Files to S3
      - name: Upload Files to S3
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          aws s3 cp infra/files/SF_HOMELESS_ANXIETY.csv s3://element84-datasets/raw/SF_HOMELESS_ANXIETY.csv
          aws s3 cp infra/files/SF_HOMELESS_DEMOGRAPHICS.csv s3://element84-datasets/raw/SF_HOMELESS_DEMOGRAPHICS.csv
